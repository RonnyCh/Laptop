{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "https://victorzhou.com/blog/keras-neural-network-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 7us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 14s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 5s 1us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "print(train_images.shape) # (60000, 28, 28)\n",
    "print(train_labels.shape) # (60000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m118954.CORPAU\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC() \n",
    "model = model.fit(train_images,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5   # this basically reduces the pixels from 255 to 0.5 max value\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "print(train_images.shape) # (60000, 784)\n",
    "print(test_images.shape)  # (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 2.3023 - accuracy: 0.1113\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 2.3016 - accuracy: 0.1124\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 2.3015 - accuracy: 0.1123\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 16s 258us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 21s 352us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 25s 414us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 2.3015 - accuracy: 0.1118\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 17s 275us/step - loss: 2.3015 - accuracy: 0.1122\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 21s 351us/step - loss: 2.3016 - accuracy: 0.1123\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 22s 372us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 2.3016 - accuracy: 0.1124\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 21s 342us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 20s 330us/step - loss: 2.3015 - accuracy: 0.1115\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 20s 339us/step - loss: 2.3016 - accuracy: 0.1123\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 21s 349us/step - loss: 2.3016 - accuracy: 0.1123\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 22s 372us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 2.3015 - accuracy: 0.1120\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 21s 351us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 20s 335us/step - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 20s 340us/step - loss: 2.3016 - accuracy: 0.1122\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 20s 332us/step - loss: 2.3015 - accuracy: 0.1117\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 21s 342us/step - loss: 2.3015 - accuracy: 0.1118\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 21s 343us/step - loss: 2.3015 - accuracy: 0.1116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b0021d0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=25,\n",
    "  batch_size=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12000 [==============================] - 0s 40us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.301229881286621, 0.11133333295583725]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n",
      "[4 0 0 8 3]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-a67e89e19eb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.dataset'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
